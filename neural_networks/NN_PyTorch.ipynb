{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiM8aMFCg7kx",
        "outputId": "31640645-b904-4dab-a192-ab8393a6dd44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"gdrive/MyDrive\")"
      ],
      "metadata": {
        "id": "AflpGWLqhEcQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./'Colab Notebooks'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJYi2u8nmtHT",
        "outputId": "14833276-08ac-4382-b41e-a86152dcdfa8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup, importing libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Checking availability of GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZnj01WdoExX",
        "outputId": "85401002-2402-43bf-8fa5-eacca905ae7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading/preprocessing data\n",
        "\n",
        "# Define dataset paths\n",
        "train_file_path = '/content/gdrive/MyDrive/data/mnist_train.csv'\n",
        "test_file_path = '/content/gdrive/MyDrive/data/mnist_test.csv'\n",
        "\n",
        "# Read the CSV files\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "# Print first 5 rows of the train and test data to check the upload\n",
        "print(\"First 5 rows of training data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"First 5 rows of test data:\")\n",
        "print(test_data.head())\n",
        "\n",
        "# Separating features and labels\n",
        "X_train = train_data.iloc[:, 1:].values / 255.0  # Normalizing pixel values\n",
        "Y_train = train_data.iloc[:, 0].values\n",
        "\n",
        "X_test = test_data.iloc[:, 1:].values / 255.0  # Normalizing pixel values\n",
        "Y_test = test_data.iloc[:, 0].values\n",
        "\n",
        "# tensor : Multi-dimensional array that is a generalization of vectors and matrices to higher dimensions\n",
        "# Fundamental data structure in PyTorch (and other DL frameworks), enabling efficient computation on GPU and CPU\n",
        "# 0-D tensor (scalar): A single number, 1-D tensor (vector): A 1D array of numbers,\n",
        "# 2-D tensor (matrix): A 2D array of numbers, N-D tensor: An N-dimensional array of numbers\n",
        "\n",
        "# converting numpy array to PyTorch tensors for usage in models and computations\n",
        "# feature tensors : torch.float32\n",
        "# label tensors : torch.int64 or torch.long\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
        "\n",
        "# Creating PyTorch datasets\n",
        "# TensorDataset combines the feature tensors and label tensors into a single dataset object\n",
        "# This object can be passed to DataLoader for iteration\n",
        "train_dataset = TensorDataset(X_train, Y_train)\n",
        "test_dataset = TensorDataset(X_test, Y_test)\n",
        "\n",
        "# train_loader / test_loader are iterators created to efficiently iterate over the datasets\n",
        "# batch_size=32 : each batch will contain 32 samples\n",
        "# shuffle=True : ensures that the model sees the training data in a different order each epoch, which helps with generalization.\n",
        "# shuffle=False : ensures that the model maintains the order of testing data for evaluation purposes.\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Print the shape of the datasets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of Y_train:\", Y_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of Y_test:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkfaYZx4osb4",
        "outputId": "def950a2-8a37-4d9a-85cb-e3cab69ead4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of training data:\n",
            "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
            "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "\n",
            "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
            "0      0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0      0  \n",
            "4      0      0      0      0      0      0      0      0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "First 5 rows of test data:\n",
            "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
            "0      7    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "1      2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "2      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "4      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
            "\n",
            "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
            "0      0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0      0  \n",
            "4      0      0      0      0      0      0      0      0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "Shape of X_train: torch.Size([60000, 784])\n",
            "Shape of Y_train: torch.Size([60000])\n",
            "Shape of X_test: torch.Size([10000, 784])\n",
            "Shape of Y_test: torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the neural network model\n",
        "# The neural network model is defined by creating a subclass of nn.Module, (base class for all\n",
        "# neural network modules in PyTorch. The class NeuralNetwork represents the architecture of the neural network.\n",
        "# super() call (nn.Module) is necessary to initialize the base class properly.\n",
        "# nn.Linear(input_dimensions, output_dimensions) for individual layers\n",
        "# activation functions (for non-linearity) -\n",
        "#   nn.Relu() : sets all negative values to zero and keeps positive values unchanged.\n",
        "#   nn.Softmax(dim=1) :\n",
        "#     converts the raw output scores into probability distribution by normalizing the values so that they sum to 1\n",
        "#     dim=1 indicates that the softmax function is applied along the dimension corresponding to the classes.\n",
        "#     typically used for the output layer of a neural network, especially in multi-class classification problems.\n",
        "#     output of Softmax function can be interpreted as the probability that the input belongs to each class.\n",
        "#     ease of interpretability for which is most likely class by selecting the one with the highest probability.\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  # forward() method defines how the input data flows through the network layers during the forward pass\n",
        "  # x : training tensor X. It is processed through the layers\n",
        "  # the result of passing through a layer while applying its respective activation functions is stored back in x,\n",
        "  # the process is repeated, and the final output x contains the probabilities for each of the 10 classes.\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.softmax(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "# creates an instance of NeuralNetwork class and .to(device) moves the model to the specified device ('device'). If\n",
        "# GPU is available, the model will moves to the GPU for faster computation. If not, it remains on the CPU.\n",
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "# commonly used for classification tasks. combines LogSoftmax and NLLLoss (Negative Log Likelihood Loss) in one single class.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# defining the optimizer to use for updating the model's weights during training.\n",
        "# Adam is an optimization algorithm that adjusts the learning rate based on the training process.\n",
        "# model.parameters(): retrieves all the parameters of the model that need to be updated.\n",
        "# lr=0.001 : setting learning rate (how much the model's weights are adjusted w.r.t. loss gradients)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Printing model summary\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkeCSwVTTrcJ",
        "outputId": "3ecf495f-6f0f-4157-bf33-4aea30f86662"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "\n",
        "# each epoch is one complete pass over the training data set\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # set the model to training mode. Important for certain layers that behave differently during\n",
        "  # training and evaluation (e.g., dropout, batch normalization)\n",
        "  model.train()\n",
        "\n",
        "  # variable to calculate the accumulated loss over each batch in the current epoch. helps to calculate average loss for the epoch.\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for X_batch, Y_batch in train_loader:\n",
        "    # Move the batch of data to the specified device (CPU or GPU) for computation to\n",
        "    # ensure that both the input data and labels are on the same device as the model.\n",
        "    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "\n",
        "    # Clearing the gradients of all optimized parameters (important because gradients accumulate by default in PyTorch)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # conducting a forward pass through the model to obtain predictions for the current batch\n",
        "    # outputs : raw output scores (logits) from the model for the current batch\n",
        "    outputs = model(X_batch)\n",
        "\n",
        "    # calculating the loss between the model's predictions and the true labels\n",
        "    # criterion: The loss function defined earlier (nn.CrossEntropyLoss())\n",
        "    # loss: The computed loss value for the current batch\n",
        "    loss = criterion(outputs, Y_batch)\n",
        "\n",
        "    # performing a backward pass to compute the gradients of the loss with respect to the model's parameters\n",
        "    # pytorch.backward() is called on the loss tensor\n",
        "    # computes the gradients of the loss with respect to each parameter (weight and bias) in the network using the chain rule\n",
        "    # of calculus. These gradients are stored in the .grad attribute of each parameter.\n",
        "    loss.backward()\n",
        "\n",
        "    # updating the model's parameters using the computed gradients. optimizer performs a step of gradient descent optimization.\n",
        "    optimizer.step()\n",
        "\n",
        "    # accumulating the loss for the current batch\n",
        "    # loss.item(): converts the loss tensor to a Python scalar and adds it to running_loss\n",
        "    running_loss += loss.item()\n",
        "\n",
        "\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"Training complete\")\n",
        "\n",
        "# Summary of Training Process\n",
        "# Set Number of Epochs: Define how many times the model will pass through the entire training dataset.\n",
        "# Epoch Loop: Iterate over the specified number of epochs.\n",
        "# Set Training Mode: Ensure the model is in training mode.\n",
        "# Batch Loop: Iterate over batches of data.\n",
        "# Move Data to Device: Transfer the data to the appropriate device (CPU/GPU).\n",
        "# Zero Gradients: Clear the accumulated gradients.\n",
        "# Forward Pass: Compute the model's predictions for the current batch.\n",
        "# Compute Loss: Calculate the loss between predictions and true labels.\n",
        "# Backward Pass: Perform backpropagation to compute gradients.\n",
        "# Update Parameters: Adjust the model's parameters based on the gradients.\n",
        "# Accumulate Loss: Keep track of the total loss for the current epoch.\n",
        "# Print Epoch Loss: Output the average loss for the current epoch.\n",
        "# End of Training: Indicate that the training process is finished.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzbF_UGOaTuT",
        "outputId": "4de74bc1-5adb-4609-aac2-44cbcb5b7d26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.6007\n",
            "Epoch [2/20], Loss: 1.5182\n",
            "Epoch [3/20], Loss: 1.5052\n",
            "Epoch [4/20], Loss: 1.4970\n",
            "Epoch [5/20], Loss: 1.4922\n",
            "Epoch [6/20], Loss: 1.4887\n",
            "Epoch [7/20], Loss: 1.4854\n",
            "Epoch [8/20], Loss: 1.4841\n",
            "Epoch [9/20], Loss: 1.4821\n",
            "Epoch [10/20], Loss: 1.4801\n",
            "Epoch [11/20], Loss: 1.4802\n",
            "Epoch [12/20], Loss: 1.4783\n",
            "Epoch [13/20], Loss: 1.4788\n",
            "Epoch [14/20], Loss: 1.4785\n",
            "Epoch [15/20], Loss: 1.4768\n",
            "Epoch [16/20], Loss: 1.4764\n",
            "Epoch [17/20], Loss: 1.4759\n",
            "Epoch [18/20], Loss: 1.4756\n",
            "Epoch [19/20], Loss: 1.4748\n",
            "Epoch [20/20], Loss: 1.4746\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating the model\n",
        "\n",
        "# Set the model to evaluation mode. This is important because certain layers, such as dropout and batch normalization,\n",
        "# behave differently during training and evaluation.\n",
        "# model.eval(): Disables dropout and uses running statistics for batch normalization instead of batch statistics.\n",
        "model.eval()\n",
        "\n",
        "# Disabling gradient computation for efficiency. During evaluation, gradients are not needed,\n",
        "# so disabling them saves memory and computation time.\n",
        "# torch.no_grad(): Context manager that disables gradient calculation.\n",
        "with torch.no_grad():\n",
        "  # initializing counters for training data\n",
        "  correct_train = 0\n",
        "  total_train = 0\n",
        "\n",
        "  # initializing counters for test data\n",
        "  correct_test = 0\n",
        "  total_test = 0\n",
        "\n",
        "  for X_batch, Y_batch in train_loader:\n",
        "    # Move the input features and labels to the appropriate device (CPU/GPU)\n",
        "    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "\n",
        "    outputs = model(X_batch)\n",
        "\n",
        "    # torch.max(outputs.data, 1) returns the index of the maximum value along the specified dimension (1 in this case,\n",
        "    # which corresponds to the class probabilities). The result is the predicted class for each sample in the batch\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # updating counters\n",
        "    total_train +=Y_batch.size(0)\n",
        "\n",
        "    correct_train += (predicted == Y_batch).sum().item()\n",
        "\n",
        "  train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "  # repeating process for test data\n",
        "\n",
        "  correct_test = 0\n",
        "  total_test = 0\n",
        "  for X_batch, Y_batch in test_loader:\n",
        "    X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
        "    outputs = model(X_batch)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_test += Y_batch.size(0)\n",
        "    correct_test += (predicted == Y_batch).sum().item()\n",
        "\n",
        "  test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "  print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
        "  print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkTrKYnb1aiA",
        "outputId": "028a3f04-b24c-409b-817c-b0b39765d199"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 98.59%\n",
            "Test Accuracy: 97.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Generate Predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  train_predictions = []\n",
        "  train_true_labels = []\n",
        "  for X_batch, Y_batch in train_loader:\n",
        "    X_batch = X_batch.to(device)\n",
        "    outputs = model(X_batch)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Convert the predicted class labels to a NumPy array and append them to train_predictions._.cpu()\n",
        "    # ensures the data is moved back to the CPU before converting to a NumPy array.\n",
        "    train_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Convert the true labels to a NumPy array and append them to train_true_labels.\n",
        "    train_true_labels.extend(Y_batch.numpy())\n",
        "\n",
        "  test_predictions = []\n",
        "  test_true_labels = []\n",
        "  for X_batch, Y_batch in test_loader:\n",
        "    X_batch = X_batch.to(device)\n",
        "    outputs = model(X_batch)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    test_predictions.extend(predicted.cpu().numpy())\n",
        "    test_true_labels.extend(Y_batch.numpy())\n",
        "\n",
        "# Convert the lists of predictions and true labels to NumPy arrays for further analysis and evaluation.\n",
        "# np.array(): Converts a list to a NumPy array.\n",
        "train_predictions = np.array(train_predictions)\n",
        "train_true_labels = np.array(train_true_labels)\n",
        "test_predictions = np.array(test_predictions)\n",
        "test_true_labels = np.array(test_true_labels)\n",
        "\n",
        "# Print the first 5 predictions and their corresponding true labels for training and test data\n",
        "print(\"First 5 training predictions:\", train_predictions[:5])\n",
        "print(\"First 5 training true labels:\", train_true_labels[:5])\n",
        "print(\"First 5 test predictions:\", test_predictions[:5])\n",
        "print(\"First 5 test true labels:\", test_true_labels[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPBJidqQJnhc",
        "outputId": "2a130f01-1689-42b7-e63e-e0ea6e8f2c6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 training predictions: [1 2 6 6 3]\n",
            "First 5 training true labels: [1 2 6 6 3]\n",
            "First 5 test predictions: [7 2 1 0 4]\n",
            "First 5 test true labels: [7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics for both datasets\n",
        "\n",
        "# Classification Report and Confusion Matrix for Training Data\n",
        "print(\"Training Classification Report:\")\n",
        "print(classification_report(train_true_labels, train_predictions))\n",
        "\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(confusion_matrix(train_true_labels, train_predictions))\n",
        "\n",
        "# Classification Report and Confusion Matrix for Test Data\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(test_true_labels, test_predictions))\n",
        "\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(confusion_matrix(test_true_labels, test_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpf5pcdfNSOB",
        "outputId": "074c93f1-6806-4b2b-a81e-eecba9ad4165"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99      5923\n",
            "           1       0.99      0.99      0.99      6742\n",
            "           2       0.99      0.98      0.98      5958\n",
            "           3       0.99      0.97      0.98      6131\n",
            "           4       0.99      0.99      0.99      5842\n",
            "           5       0.96      0.99      0.98      5421\n",
            "           6       1.00      0.99      0.99      5918\n",
            "           7       0.98      0.99      0.99      6265\n",
            "           8       0.98      0.98      0.98      5851\n",
            "           9       0.98      0.98      0.98      5949\n",
            "\n",
            "    accuracy                           0.99     60000\n",
            "   macro avg       0.99      0.99      0.99     60000\n",
            "weighted avg       0.99      0.99      0.99     60000\n",
            "\n",
            "Training Confusion Matrix:\n",
            "[[5850    1    9    2    3    9    9   22   14    4]\n",
            " [   1 6690   11    4    4    2    2    5    7   16]\n",
            " [   5   27 5834   22    8    1    3   24   24   10]\n",
            " [   0    1   26 5975    2   88    1    8   13   17]\n",
            " [   1    2    3    0 5786    1    5    8    7   29]\n",
            " [   3    0    2    9    5 5376    6    5    9    6]\n",
            " [   6    4    1    0   10   49 5844    0    4    0]\n",
            " [   1    8    9   11   11    1    0 6202    8   14]\n",
            " [   3   11    1   19    5   41    2    4 5739   26]\n",
            " [   5    2    0    1   40   16    0   22    7 5856]]\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.98      0.97      0.97      1032\n",
            "           3       0.98      0.96      0.97      1010\n",
            "           4       0.96      0.98      0.97       982\n",
            "           5       0.93      0.99      0.96       892\n",
            "           6       0.99      0.96      0.97       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.97      0.96      0.97       974\n",
            "           9       0.97      0.96      0.97      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n",
            "Test Confusion Matrix:\n",
            "[[ 960    0    2    3    0    4    1    6    2    2]\n",
            " [   0 1125    2    2    0    0    1    1    4    0]\n",
            " [   4    4  996    4    1    0    2   10   11    0]\n",
            " [   0    1    1  971    1   25    0    4    2    5]\n",
            " [   0    0    2    0  961    0    6    1    2   10]\n",
            " [   2    0    0    1    1  884    1    1    1    1]\n",
            " [   6    2    2    0   11   18  915    2    2    0]\n",
            " [   1    5    5    5    2    1    0  998    2    9]\n",
            " [   2    1    2    6    4   11    1    5  936    6]\n",
            " [   2    2    0    3   16   10    1    3    0  972]]\n"
          ]
        }
      ]
    }
  ]
}